{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from qdrant_client import QdrantClient, models\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Do this to enable importing modules\n",
    "src_path = os.path.join(os.path.abspath(\"\"), \"..\")\n",
    "sys.path.insert(0, src_path)\n",
    "\n",
    "from feature_pipeline.settings import settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLEAN_COLLECTION = False\n",
    "\n",
    "_client = QdrantClient(\n",
    "    host=settings.QDRANT_DATABASE_HOST,\n",
    "    port=settings.QDRANT_DATABASE_PORT,\n",
    ")\n",
    "\n",
    "_client.delete(\n",
    "    collection_name=\"cleaned_articles\",\n",
    "    points_selector=models.FilterSelector(\n",
    "        filter=models.Filter(\n",
    "            must=[\n",
    "                models.FieldCondition(\n",
    "                    key=\"source\",\n",
    "                    match=models.MatchValue(value=\"news_api\"),\n",
    "                ),\n",
    "            ],\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "\n",
    "if CLEAN_COLLECTION:\n",
    "    _client.delete_collection(collection_name=\"cleaned_articles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_pipeline.db.qdrant import connection as client\n",
    "    \n",
    "def fetch_all_cleaned_content(collection_name: str) -> list:\n",
    "        all_cleaned_contents = []\n",
    "\n",
    "        scroll_response = client.scroll(collection_name=collection_name, limit=10000)\n",
    "        points = scroll_response[0]\n",
    "\n",
    "        for point in points:\n",
    "            # cleaned_content = point.payload[\"cleaned_content\"]\n",
    "            cleaned_content = point.payload\n",
    "            if cleaned_content:\n",
    "                all_cleaned_contents.append(cleaned_content)\n",
    "\n",
    "        return all_cleaned_contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles = fetch_all_cleaned_content(\"cleaned_articles\")\n",
    "len(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "\n",
    "i = 2\n",
    "\n",
    "# for article in articles:\n",
    "#     wrapped_string = textwrap.fill(article[\"cleaned_content\"], width=100)\n",
    "#     print(\"\\n\")\n",
    "#     print(article[\"source\"])\n",
    "#     print(wrapped_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_PROMPT = (\n",
    "    f\"I will give you batches of contents of articles. Please generate me exactly 1 instruction for each of them. The article \"\n",
    "    f\"for which you have to generate the instructions is under Content number x lines. Please structure the answer in json format,\"\n",
    "    f\"ready to be loaded by json.loads(), a list of objects only with fields called instruction and content. For the content field, copy the number of the content only!.\"\n",
    "    f\"Please do not add any extra characters and make sure it is a list with objects in valid json format!\\n\"\n",
    ")\n",
    "\n",
    "\n",
    "class DataFormatter:\n",
    "    @classmethod\n",
    "    def format_data(cls, data_points: list, is_example: bool, start_index: int) -> str:\n",
    "        text = \"\"\n",
    "        for index, data_point in enumerate(data_points):\n",
    "            if not is_example:\n",
    "                text += f\"Content number {start_index + index }\\n\"\n",
    "            text += str(data_point) + \"\\n\"\n",
    "        return text\n",
    "\n",
    "    @classmethod\n",
    "    def format_batch(cls, context_msg: str, data_points: list, start_index: int) -> str:\n",
    "        delimiter_msg = context_msg\n",
    "        delimiter_msg += cls.format_data(data_points, False, start_index)\n",
    "        return delimiter_msg\n",
    "\n",
    "    @classmethod\n",
    "    def format_prompt(cls, inference_posts: list, start_index: int):\n",
    "        initial_prompt = USER_PROMPT\n",
    "        initial_prompt += f\"You must generate exactly a list of {len(inference_posts)} json objects, using the contents provided under CONTENTS FOR GENERATION\\n\"\n",
    "        initial_prompt += cls.format_batch(\n",
    "            \"\\nCONTENTS FOR GENERATION: \\n\", inference_posts, start_index\n",
    "        )\n",
    "        return initial_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import logging\n",
    "import json\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "\n",
    "MAX_LENGTH = 16384\n",
    "SYSTEM_PROMPT = \"You are a news writer whose job is reporting about the cryptocurrency market trends and developments\"\n",
    "\n",
    "class OpenAIHandler:\n",
    "    def __init__(self, gpt_model: str = \"gpt-3.5-turbo\"):\n",
    "        self.api_key = settings.OPENAI_API_KEY\n",
    "        self.gpt_model = gpt_model\n",
    "\n",
    "    def request(self, prompt: str) -> list:\n",
    "            try:\n",
    "                client = OpenAI(api_key=self.api_key)\n",
    "                logging.info(\"Sending batch to LLM\")\n",
    "                chat_completion = client.chat.completions.create(\n",
    "                    messages=[\n",
    "                        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "                        {\"role\": \"user\", \"content\": prompt[:MAX_LENGTH]},\n",
    "                    ],\n",
    "                    model=self.gpt_model,\n",
    "                )\n",
    "                response = chat_completion.choices[0].message.content\n",
    "                return json.loads(self.clean_response(response))\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Skipping batch! An error occurred while communicating with API: {e}\")\n",
    "                return []\n",
    "\n",
    "    @staticmethod\n",
    "    def clean_response(response: str) -> str:\n",
    "        start_index = response.find(\"[\")\n",
    "        end_index = response.rfind(\"]\")\n",
    "        return response[start_index : end_index + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OpenAIHandler().clean_response(\"some text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-23 12:57:14,567 - INFO - Sending batch to LLM\n",
      "2024-05-23 12:57:17,614 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-05-23 12:59:14,350 - ERROR - Skipping batch! An error occurred while communicating with API: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OpenAIHandler().request(\"Bitcoin crash 2024\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetGenerator:\n",
    "    def __init__(\n",
    "        self,\n",
    "        api_communicator: OpenAIHandler,\n",
    "        data_formatter: DataFormatter,\n",
    "    ):\n",
    "        self.api_communicator = api_communicator\n",
    "        self.data_formatter = data_formatter\n",
    "\n",
    "    def generate_training_data(self, collection_name: str, batch_size: int = 1):\n",
    "        all_contents = self.fetch_all_cleaned_content(collection_name)\n",
    "        response = []\n",
    "        for i in range(0, len(all_contents), batch_size):\n",
    "            batch = all_contents[i : i + batch_size]\n",
    "            initial_prompt = self.data_formatter.format_prompt(batch, i)\n",
    "            response += self.api_communicator.request(initial_prompt)\n",
    "            for j in range(i, i + batch_size):\n",
    "                response[j][\"content\"] = all_contents[j]\n",
    "\n",
    "        # self.push_to_comet(response, collection_name)\n",
    "        return response\n",
    "    \n",
    "    def fetch_all_cleaned_content(self, collection_name: str) -> list:\n",
    "        all_cleaned_contents = []\n",
    "\n",
    "        scroll_response = client.scroll(collection_name=collection_name, limit=10000)\n",
    "        points = scroll_response[0]\n",
    "\n",
    "        for point in points:\n",
    "            cleaned_content = point.payload[\"cleaned_content\"]\n",
    "            # cleaned_content = point.payload\n",
    "            if cleaned_content:\n",
    "                all_cleaned_contents.append(cleaned_content)\n",
    "\n",
    "        return all_cleaned_contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hong Kongs Office of the Privacy Commissioner for Personal Data (PCPD) has concluded its inquiry into the Worldcoin project, determining that its operations in Hong Kong violated its Personal Data (Privacy) Ordinance (PDPO). In a May 22 notice, Privacy Commissioner Ada Chung Lai-lingissued an enforcement notice to Worldcoin, ordering the immediate halt of all project operations in Hong Kong that involve scanning and collecting iris and facial images of the public using iris scanning devices. The PCPD started its investigationagainst the Worldcoin project in January 2024 to determine whether the identity verification methods posed serious risks to citizens personal data privacy and violated the requirements of the PDPO. The PCPD conducted 10 covert visits at six premises involved in operating the Worldcoin project from December 2023 to January 2024. According to the PCPD, collecting face images was unnecessary for verifying the humanness of participants, as the iris scanning device operators were already capable of performing this verification in person at the operating locations, making the scanning or collection of face images an unnecessary step. The PCPD also pointed out that Worldcoin failed to provide sufficient information, preventing informed decisions and genuine consent.  The investigation revealed that Worldcoins privacy notice was unavailable in Chinese, which meant non-English speaking participants could not understand the projects policies, practices, terms and conditions. The PCPD said: Under these circumstances, the PCPD deemed the collection of face and iris images unfair and unlawful, violating its data protection principles. Related: Worldcoin beefs up security by open-sourcing biometric data system The PCPD ruled that Worldcoins retention of sensitive biometric data for up to 10 years solely for AI model training, including face and iris images, was unjustified.  Worldcoin confirmed that 8,302 individuals had their faces and irises scanned for verification during its operation in Hong Kong. The project was announced in 2021, with more than two million people signing up before the projects official launch in July 2023. Worldcoin has attracted the attention of regulators in many countriesover privacy concerns, leading to thesuspension of services in Kenya and the pausing of iris scans in India. Magazine: Moral responsibility: Can blockchain really improve trust in AI? Add reaction'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles[0][\"cleaned_content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I will give you batches of contents of articles. Please generate me exactly 1 instruction for each of them. The article for which you have to generate the instructions is under Content number x lines. Please structure the answer in json format,ready to be loaded by json.loads(), a list of objects only with fields called instruction and content. For the content field, copy the number of the content only!.Please do not add any extra characters and make sure it is a list with objects in valid json format!\n",
      "You must generate exactly a list of 1 json objects, using the contents provided under CONTENTS FOR GENERATION\n",
      "\n",
      "CONTENTS FOR GENERATION: \n",
      "Content number 0\n",
      "Hong Kongs Office of the Privacy Commissioner for Personal Data (PCPD) has concluded its inquiry into the Worldcoin project, determining that its operations in Hong Kong violated its Personal Data (Privacy) Ordinance (PDPO). In a May 22 notice, Privacy Commissioner Ada Chung Lai-lingissued an enforcement notice to Worldcoin, ordering the immediate halt of all project operations in Hong Kong that involve scanning and collecting iris and facial images of the public using iris scanning devices. The PCPD started its investigationagainst the Worldcoin project in January 2024 to determine whether the identity verification methods posed serious risks to citizens personal data privacy and violated the requirements of the PDPO. The PCPD conducted 10 covert visits at six premises involved in operating the Worldcoin project from December 2023 to January 2024. According to the PCPD, collecting face images was unnecessary for verifying the humanness of participants, as the iris scanning device operators were already capable of performing this verification in person at the operating locations, making the scanning or collection of face images an unnecessary step. The PCPD also pointed out that Worldcoin failed to provide sufficient information, preventing informed decisions and genuine consent.  The investigation revealed that Worldcoins privacy notice was unavailable in Chinese, which meant non-English speaking participants could not understand the projects policies, practices, terms and conditions. The PCPD said: Under these circumstances, the PCPD deemed the collection of face and iris images unfair and unlawful, violating its data protection principles. Related: Worldcoin beefs up security by open-sourcing biometric data system The PCPD ruled that Worldcoins retention of sensitive biometric data for up to 10 years solely for AI model training, including face and iris images, was unjustified.  Worldcoin confirmed that 8,302 individuals had their faces and irises scanned for verification during its operation in Hong Kong. The project was announced in 2021, with more than two million people signing up before the projects official launch in July 2023. Worldcoin has attracted the attention of regulators in many countriesover privacy concerns, leading to thesuspension of services in Kenya and the pausing of iris scans in India. Magazine: Moral responsibility: Can blockchain really improve trust in AI? Add reaction\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check prompt\n",
    "prompt = DataFormatter.format_prompt([articles[0][\"cleaned_content\"]], 0)\n",
    "import textwrap\n",
    "# print(textwrap.fill(prompt, 150))\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-23 13:50:39,334 - INFO - HTTP Request: POST http://localhost:6333/collections/cleaned_articles/points/scroll \"HTTP/1.1 200 OK\"\n",
      "2024-05-23 13:50:39,349 - INFO - Sending batch to LLM\n",
      "2024-05-23 13:50:41,098 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-05-23 13:50:41,113 - INFO - Sending batch to LLM\n",
      "2024-05-23 13:50:42,735 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-05-23 13:50:42,753 - INFO - Sending batch to LLM\n",
      "2024-05-23 13:50:44,685 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-05-23 13:50:44,698 - INFO - Sending batch to LLM\n",
      "2024-05-23 13:50:45,806 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-05-23 13:50:45,818 - INFO - Sending batch to LLM\n",
      "2024-05-23 13:50:46,933 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-05-23 13:50:46,946 - INFO - Sending batch to LLM\n",
      "2024-05-23 13:50:48,881 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-05-23 13:50:48,903 - INFO - Sending batch to LLM\n",
      "2024-05-23 13:50:50,213 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-05-23 13:50:50,233 - INFO - Sending batch to LLM\n",
      "2024-05-23 13:50:51,746 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-05-23 13:50:51,765 - INFO - Sending batch to LLM\n",
      "2024-05-23 13:50:53,071 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "response = DatasetGenerator(\n",
    "    api_communicator=OpenAIHandler(),\n",
    "    data_formatter=DataFormatter()    \n",
    ").generate_training_data(\"cleaned_articles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'instruction': 'Investigate the Worldcoin project and determine whether their operations in Hong Kong violated the Personal Data (Privacy) Ordinance, as concluded by the Office of the Privacy Commissioner for Personal Data (PCPD)',\n",
       "  'content': 'Hong Kongs Office of the Privacy Commissioner for Personal Data (PCPD) has concluded its inquiry into the Worldcoin project, determining that its operations in Hong Kong violated its Personal Data (Privacy) Ordinance (PDPO). In a May 22 notice, Privacy Commissioner Ada Chung Lai-lingissued an enforcement notice to Worldcoin, ordering the immediate halt of all project operations in Hong Kong that involve scanning and collecting iris and facial images of the public using iris scanning devices. The PCPD started its investigationagainst the Worldcoin project in January 2024 to determine whether the identity verification methods posed serious risks to citizens personal data privacy and violated the requirements of the PDPO. The PCPD conducted 10 covert visits at six premises involved in operating the Worldcoin project from December 2023 to January 2024. According to the PCPD, collecting face images was unnecessary for verifying the humanness of participants, as the iris scanning device operators were already capable of performing this verification in person at the operating locations, making the scanning or collection of face images an unnecessary step. The PCPD also pointed out that Worldcoin failed to provide sufficient information, preventing informed decisions and genuine consent.  The investigation revealed that Worldcoins privacy notice was unavailable in Chinese, which meant non-English speaking participants could not understand the projects policies, practices, terms and conditions. The PCPD said: Under these circumstances, the PCPD deemed the collection of face and iris images unfair and unlawful, violating its data protection principles. Related: Worldcoin beefs up security by open-sourcing biometric data system The PCPD ruled that Worldcoins retention of sensitive biometric data for up to 10 years solely for AI model training, including face and iris images, was unjustified.  Worldcoin confirmed that 8,302 individuals had their faces and irises scanned for verification during its operation in Hong Kong. The project was announced in 2021, with more than two million people signing up before the projects official launch in July 2023. Worldcoin has attracted the attention of regulators in many countriesover privacy concerns, leading to thesuspension of services in Kenya and the pausing of iris scans in India. Magazine: Moral responsibility: Can blockchain really improve trust in AI? Add reaction'},\n",
       " {'instruction': \"Write an article about the potential approval of a spot Ether exchange-traded fund (ETF) by the SEC, focusing on VanEck's ETF listing by DTCC under the ticker symbol ETHV and the speculation surrounding the decision date on May 23.\",\n",
       "  'content': 'Amid increasing speculation about the possible approval of a spot Ether exchange-traded fund (ETF) in the United States on May 23, global investment manager VanEcks ETF has been listed by the Depository Trust and Clearing Corporation (DTCC) under the ticker symbol ETHV. The DTCC is an American financial market infrastructure provider that offers clearing, settlement and transaction reporting services to financial market players. A listing on DTCC is considered a crucial step before final approval from the U.S. Securities and Exchange Commission (SEC).  VanEcks ETF is currently designated inactive on the DTCC website, meaning it cannot be processed until it receives the necessary regulatory approvals. However, VanEck is not the first Ether  ETH  $3,745  ETF listed by the DTCC. Franklin Templetonsspot ETH ETF was listed on the platform a month ago.  ETH   $3,745  The DTCC said that the ETF list includes both active ETFs that may be processed by the DTCC and ETFs that are not yet active and, therefore, cannot be processed. Another report suggested that SEC officials contacted Nasdaq, the Chicago Board Options Exchange and the New York Stock Exchange to update and change existing spot Ether ETF applications. Related: Crypto insiders anxious and divided as spot Ether ETF decision date looms The significant change in the SECs stance over the past week is speculated to be linked to the White House.  Crypto lawyer Jake Chervinsky noted in a post on X that policy is driven by politics, and for months, crypto has been winning the political battle. He also speculated that former president Donald Trumps endorsement of cryptocurrency compelled the administration of President Joe Biden to shift its policy.  May 23 is the final deadline for the SECs decision on the VanEck spot Ether ETF application. After months of speculation about a probable denial of spot ETH ETFs, the SEC took action earlier this week.  The SEC firstasked financial managers to amend and refile their 19b-4 filings on their proposed spot Ether ETFs. Some analysts saw the move as a positive sign, swinging the potential chance of approval to 75% from 25%. Magazine: What do crypto market makers actually do? Liquidity, or manipulation Add reaction'},\n",
       " {'instruction': 'Write a detailed report on the sentencing memo filed by United States prosecutors for former FTX executive Ryan Salame, highlighting the demands for a 5 to 7-year prison term and the implications of his involvement in the collapse of the FTX crypto exchange.',\n",
       "  'content': 'United States prosecutors want former FTX executive Ryan Salame  the alleged wingman of FTX co-founder Sam SBF Bankman-Fried  to serve five to seven years in prison for crimes that led to the eventual collapse of the FTX crypto exchange. On May 21, federal prosecutors filed a sentencing memo in a Manhattan federal court demanding strict sentencing for Salame after the defendant pleaded guilty to committing serious crimes linked to misappropriating FXT investors funds.  In the court filing viewed by Bloomberg, the U.S. prosecutors demanded just punishment fitting the scale of his crime as opposed to Salames lawyers, who argue that he should serve no more than 18 months. The prosecutors said: Salames court sentencing for helping SBF siphon $10 billion of users funds is currently set for May 28. The prosecutors added: Only a meaningful period of incarceration could adequately deter the defendant and others and promote respect for the law. On April 1, the U.S. District Court for the Southern District of New York sentenced SBF to 25 years in prison following his conviction on seven felony charges. Salame will be SBFs first accomplice to get sentenced.  Salame started working for Alameda Research in Hong Kong in 2019 and later climbed the corporate ladder to become the CEO of FTX Digital Markets, the FTX subsidiary based in the Bahamas. Other prominent members running the FTX scam  Caroline Ellison, Nishad Singh and Gary Wang  are yet to be sentenced. Related: SBF maintains his innocence as he trades rice in jail Numerous U.S. lawmakers are supporting a bill that aims to clarify the roles of the countrys financial regulators regarding digital assets to prevent the next FTX from happening, according to North Carolina Representative Wiley Nickel. Nickel called on lawmakers to support the passage of the Financial Innovation and Technology for the 21st Century (FIT21) Act, a bill that would clarify how the Securities and Exchange Commission and Commodity Futures Trading Commission regulate crypto. Magazine: The $2,500 doco about FTX collapse on Amazon Prime with help from mom Add reaction'},\n",
       " {'instruction': 'Write about the surge of PEPE reaching new high amidst ETH price jump on renewed ETF approval hope',\n",
       "  'content': 'PEPE reaches new high amid ETH price jump on renewed ETF approval hope\\n\\n$ETH is up 23.28% over the past two days to $3,785 amid renewed hope that the SEC is moving to approve Ether ETFs by a May 23 deadline  an unexpected turn of events for analysts and the crypto industry.\\n\\n$PEPE is up 23.48% over the past 24 hour.\\n\\nDid you ride this pump?\\n\\n  - Yep, took some profits.\\n\\n  - Nope, Im just HODLing.'},\n",
       " {'instruction': 4,\n",
       "  'content': \"BlackRock's Bitcoin ETF hits 6-week inflow high amid early-week BTC rally\\n\\nBlackRock's IBIT recorded $290 million in inflow on Tuesday, more than the fund has seen in the past 21 trading days combined. \\n\\n  Read More\"},\n",
       " {'instruction': \"Discuss Ethereum co-founder Vitalik Buterin's support for implementing zero-knowledge (ZK) likes on the decentralized social media platform Farcaster to combat preference falsification and how it aligns with the platform's principles.\",\n",
       "  'content': 'Ethereum co-founder Vitalik Buterin expressed his support for X engineer Haofeis announcement on the decentralized social media platform Farcaster. Haofei revealed that X will be making Likes private. On May 20, Buterin took the idea further, suggesting that Farcaster should implement zero-knowledge (ZK) likes to combat preference falsification  the misrepresentation of true preference due to social pressure or fear. ZK technology is a privacy-preserving cryptography technique that allows one party to prove to another that a statement is true without revealing confidential information. When applied to likes, it would prove someone has liked a post without revealing their identity. Buterin suggested borrowing ZK technology from Zupoll, a tool used within the pop-up city concept, which Buterin initiated and dubbed Zuzalu. Geared toward decentralization and cryptography, Zupoll is used for anonymous voting and poll decision-making. The suggestion to use ZK technology Buterin put forward aligns with the principles behind the Farcaster platform: user privacy, censorship resistance, autonomy, and the distinction from centralized social media platforms. In response to rumors that X might be hiding users likes by default, Haofei confirmed that the platform would be making likes private and explained the rationale behind this: Haofei continued, stating that users would soon be able to like posts without worrying who might see it. He also reminded users that the more posts you like, the better for you the algorithm will become. Community responses to the news were mixed. Some users suggested the idea be taken further, stating, Why stop at likes? Following is the same. High-profile accounts like Wall Street Silver posed a contrasting opinion. Related:White paper that birthed crypto ZK-proofs receives IEEE Test of Time award Outside of the field of ZK cryptography, Buterin has recently suggested solutions to mitigate the miner extracted value (MEV) problem.Through MEV strategies, validators can accrue profits by arranging the transactions within a block to seize otherwise inaccessible arbitrage opportunities. However, this practice congests the network, increases trader slippage requirements, and increases gas fees. To combat this, Buterin suggested the use of MEV minimization quarantine techniques, the use of inclusions lists, and reduced requirements to run a node. Magazine:If Bitcoin doubles, Stacks will 4x in 2025: Daan Crypto Trades, X Hall of Flame Add reaction'},\n",
       " {'instruction': 'Write a news article about the Gala Games exploiter who returned $22M from a GALA token attack',\n",
       "  'content': 'Gala Games exploiter returns $22M from GALA token attack\\n\\nOn Monday, an attacker minted $200 million worth of GALA tokens but managed to sell only a portion of them. Its just been returned. \\n\\n  Read More'},\n",
       " {'instruction': 'Investigate the accusations against Rabbit AI company for NFT scam and concealing information by YouTube investigator Stephen Findeisen, and seek comments from Rabbit regarding the allegations.',\n",
       "  'content': 'YouTube investigator Stephen Findeisen, better known as Coffeezilla, has accused the artificial intelligence (AI) company Rabbit of orchestrating a nonfungible token (NFT) scam and attempting to conceal it. On May 21, Findeisen published a video on the Coffeezilla channel revealing Rabbit AIs involvement in NFTs. The YouTube sleuth pointed out that the company was previously called Cyber Manufacture Co. and raised $6 million for an NFT project called Gama.  However, a few years later, Rabbit AIs founder and CEO Jesse Lyu drew a line between crypto and the companys new image. Findeisen highlighted Lyus Discord statements saying the company will never touch crypto.  Cointelegraph has approached Rabbit for comment. Lyu also explained that Gama was only a fun little project he was involved with during the COVID-19 pandemic. The Rabbit founder wrote that he left the project once the game they did was open-sourced.  While Lyu downplayed Gama as a small project, Findeisen revealed recordings of Lyu explaining their grand vision for the NFT endeavor. In the recordings, Lyu said they were dumping millions into the project to ensure Gama becomes a next-level experience. Lyu said: Because of Lyus promises, Findeisen questioned where the $6 million funding raised for the Gama project went. According to Coffeezilla, the company claimed the funds were only used for the NFT project.  Related: YouTuber KSI faces pump-and-dump allegations from ZachXBT and Coffeezilla Despite this, Coffeezilla said it should still concern Rabbit as its built on the remains of the Gama project. Findeisen also highlighted that the companys viral R1 product was also overhyped. He said:  Apart from Findeisen, others believe that Rabbits R1 product is an AI grift. On Jan. 14, WeGPT founder and CEO Josh Olin alleged on X that Rabbits project was a scam. Olin described the companys product as a quick cash grab that aimed to bait investors.  Magazine: Bybits Notcoin listing debacle, China firms profits up 12-fold after crypto buy: Asia Express Add reaction'},\n",
       " {'instruction': \"Write a news report detailing the order for Worldcoin to cease operations in Hong Kong, following the PCPD's ruling on the retention of sensitive biometric data for AI model training.\",\n",
       "  'content': 'Worldcoin ordered to stop operations in Hong Kong \\n\\nThe PCPD ruled that Worldcoins retention of sensitive biometric data, including face and iris images, for up to 10 years solely for AI model training was unjustified.\\n\\n  Read more'}]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-system-_6t_t_f9-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
