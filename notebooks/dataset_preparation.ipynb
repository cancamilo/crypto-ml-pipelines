{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from qdrant_client import QdrantClient, models\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Do this to enable importing modules\n",
    "src_path = os.path.join(os.path.abspath(\"\"), \"..\")\n",
    "sys.path.insert(0, src_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MongoDb data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-04 17:29:17,016 - INFO - {\"message\": \"Waiting for suitable server to become available\", \"selector\": \"<function writable_server_selector at 0x17ff21e10>\", \"operation\": \"drop\", \"topologyDescription\": \"<TopologyDescription id: 665f32cdbf60523316ad4cd8, topology_type: ReplicaSetNoPrimary, servers: [<ServerDescription ('localhost', 30001) server_type: Unknown, rtt: None>, <ServerDescription ('localhost', 30002) server_type: Unknown, rtt: None>, <ServerDescription ('localhost', 30003) server_type: Unknown, rtt: None>]>\", \"clientId\": {\"$oid\": \"665f32cdbf60523316ad4cd8\"}, \"remainingTimeMS\": 29}\n"
     ]
    }
   ],
   "source": [
    "CLEAN_MONGODB = True\n",
    "\n",
    "if CLEAN_MONGODB:\n",
    "    from pymongo import MongoClient\n",
    "    host = \"mongodb://localhost:30001,localhost:30002,localhost:30003/?replicaSet=my-replica-set\"\n",
    "    mongo_client = MongoClient(host)\n",
    "\n",
    "    db = mongo_client[\"crypto-articles\"]\n",
    "    db[\"articles\"].drop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qdrant Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-04 18:20:02,938 - INFO - HTTP Request: GET http://localhost:6333/collections \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CollectionsResponse(collections=[CollectionDescription(name='cleaned_articles'), CollectionDescription(name='vector_articles')])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from finetuning.settings import settings\n",
    "from qdrant_client.http.models import Batch, Distance, VectorParams\n",
    "\n",
    "EMBEDDING_SIZE=384\n",
    "CLEAN_COLLECTION = False\n",
    "\n",
    "_client = QdrantClient(\n",
    "    host=settings.QDRANT_DATABASE_HOST,\n",
    "    port=settings.QDRANT_DATABASE_PORT,\n",
    ")\n",
    "\n",
    "\n",
    "if CLEAN_COLLECTION:\n",
    "    _client.delete_collection(collection_name=\"cleaned_articles\")\n",
    "    _client.delete_collection(collection_name=\"vector_articles\")\n",
    "\n",
    "    _client.create_collection(collection_name=\"cleaned_articles\", vectors_config={})\n",
    "    _client.create_collection(collection_name=\"vector_articles\", vectors_config=VectorParams(size=EMBEDDING_SIZE, distance=Distance.COSINE))\n",
    "\n",
    "_client.get_collections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "\n",
    "i = 2\n",
    "\n",
    "# for article in articles:\n",
    "#     wrapped_string = textwrap.fill(article[\"cleaned_content\"], width=100)\n",
    "#     print(\"\\n\")\n",
    "#     print(article[\"source\"])\n",
    "#     print(wrapped_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-04 17:09:14,137 - INFO - trying to connect to qdrant\n",
      "2024-06-04 17:09:14,138 - INFO - host\n",
      "2024-06-04 17:09:14,138 - INFO - localhost\n",
      "2024-06-04 17:09:14,138 - INFO - port\n",
      "2024-06-04 17:09:14,138 - INFO - 6333\n"
     ]
    }
   ],
   "source": [
    "from finetuning.utils.openai_helper import OpenAIHandler\n",
    "from finetuning.utils.data_formatter import DataFormatter\n",
    "from finetuning.data_generator import DatasetGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_name = \"cleaned_articles\"\n",
    "openai_handler = OpenAIHandler()\n",
    "formatter = DataFormatter()\n",
    "generator = DatasetGenerator(openai_handler, formatter)\n",
    "all_contents = generator.fetch_all_cleaned_content(collection_name)\n",
    "training_data = generator.generate_training_data(all_contents[:10], 1)\n",
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-04 17:14:31,782 - INFO - Starting to push data to Comet: cleaned_articles\n",
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/cancamilo/crypto-reporter/49e2cc8a14ec48d789aa7b2e46374f10\n",
      "\n",
      "2024-06-04 17:14:35,687 - INFO - Writing data to file: cleaned_articles.json\n",
      "2024-06-04 17:14:35,688 - INFO - Data written to file successfully\n",
      "2024-06-04 17:14:35,689 - INFO - Artifact created and file added: cleaned_articles.json\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Artifact 'cleaned_articles' version 2.0.0 created (previous was: 1.0.0)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Scheduling the upload of 1 assets for a size of 14.42 KB, this can take some time\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Artifact 'cancamilo/cleaned_articles:2.0.0' has started uploading asynchronously\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name                  : normal_ocean_9191\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/cancamilo/crypto-reporter/49e2cc8a14ec48d789aa7b2e46374f10\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     artifact assets          : 1 (14.42 KB)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     artifacts                : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details      : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename                 : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     git metadata             : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     git-patch (uncompressed) : 1 (797.87 KB)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages       : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook                 : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code              : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Artifact 'cancamilo/cleaned_articles:2.0.0' has been fully uploaded successfully\n",
      "2024-06-04 17:14:38,978 - INFO - Data pushed to Comet successfully and experiment ended\n"
     ]
    }
   ],
   "source": [
    "generator.push_to_comet(training_data, collection_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-04 17:00:12,985 - INFO - HTTP Request: POST http://localhost:6333/collections/cleaned_articles/points/scroll \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_articles = generator.fetch_all_cleaned_content(\"cleaned_articles\")\n",
    "len(cleaned_articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "all_contents = cleaned_articles[140:150]\n",
    "batch_size = 1\n",
    "\n",
    "\n",
    "openai_handler = OpenAIHandler()\n",
    "formatter = DataFormatter()\n",
    "\n",
    "response = []\n",
    "\n",
    "for i in range(0, len(all_contents), batch_size):\n",
    "    batch = all_contents[i : i + batch_size]\n",
    "    initial_prompt = formatter.format_prompt(batch, i)\n",
    "    print(initial_prompt)\n",
    "    batch_result = openai_handler.request(initial_prompt)\n",
    "\n",
    "    # only process batch if response is valid\n",
    "    if len(batch_result) > 0:\n",
    "        response += batch_result\n",
    "        for j in range(i, i + batch_size):\n",
    "            response[j][\"content\"] = all_contents[j]\n",
    "\n",
    "# self.push_to_comet(response, collection_name)\n",
    "response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>323.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>175.275542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>98.662932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>112.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>169.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>219.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1023.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            length\n",
       "count   323.000000\n",
       "mean    175.275542\n",
       "std      98.662932\n",
       "min      13.000000\n",
       "25%     112.000000\n",
       "50%     169.000000\n",
       "75%     219.000000\n",
       "max    1023.000000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(cleaned_articles, columns=[\"content\"])\n",
    "df[\"length\"] = df[\"content\"].apply(lambda x: len(x.split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"content\"].isna().sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-system-_6t_t_f9-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
