{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from qdrant_client import QdrantClient, models\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Do this to enable importing modules\n",
    "src_path = os.path.join(os.path.abspath(\"\"), \"..\")\n",
    "sys.path.insert(0, src_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MongoDb data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-04 17:29:17,016 - INFO - {\"message\": \"Waiting for suitable server to become available\", \"selector\": \"<function writable_server_selector at 0x17ff21e10>\", \"operation\": \"drop\", \"topologyDescription\": \"<TopologyDescription id: 665f32cdbf60523316ad4cd8, topology_type: ReplicaSetNoPrimary, servers: [<ServerDescription ('localhost', 30001) server_type: Unknown, rtt: None>, <ServerDescription ('localhost', 30002) server_type: Unknown, rtt: None>, <ServerDescription ('localhost', 30003) server_type: Unknown, rtt: None>]>\", \"clientId\": {\"$oid\": \"665f32cdbf60523316ad4cd8\"}, \"remainingTimeMS\": 29}\n"
     ]
    }
   ],
   "source": [
    "CLEAN_MONGODB = True\n",
    "\n",
    "if CLEAN_MONGODB:\n",
    "    from pymongo import MongoClient\n",
    "    host = \"mongodb://localhost:30001,localhost:30002,localhost:30003/?replicaSet=my-replica-set\"\n",
    "    mongo_client = MongoClient(host)\n",
    "\n",
    "    db = mongo_client[\"crypto-articles\"]\n",
    "    db[\"articles\"].drop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qdrant Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-04 18:20:02,938 - INFO - HTTP Request: GET http://localhost:6333/collections \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CollectionsResponse(collections=[CollectionDescription(name='cleaned_articles'), CollectionDescription(name='vector_articles')])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from finetuning.settings import settings\n",
    "from qdrant_client.http.models import Batch, Distance, VectorParams\n",
    "\n",
    "EMBEDDING_SIZE=384\n",
    "CLEAN_COLLECTION = False\n",
    "\n",
    "_client = QdrantClient(\n",
    "    host=settings.QDRANT_DATABASE_HOST,\n",
    "    port=settings.QDRANT_DATABASE_PORT,\n",
    ")\n",
    "\n",
    "\n",
    "if CLEAN_COLLECTION:\n",
    "    _client.delete_collection(collection_name=\"cleaned_articles\")\n",
    "    _client.delete_collection(collection_name=\"vector_articles\")\n",
    "\n",
    "    _client.create_collection(collection_name=\"cleaned_articles\", vectors_config={})\n",
    "    _client.create_collection(collection_name=\"vector_articles\", vectors_config=VectorParams(size=EMBEDDING_SIZE, distance=Distance.COSINE))\n",
    "\n",
    "_client.get_collections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "\n",
    "i = 2\n",
    "\n",
    "# for article in articles:\n",
    "#     wrapped_string = textwrap.fill(article[\"cleaned_content\"], width=100)\n",
    "#     print(\"\\n\")\n",
    "#     print(article[\"source\"])\n",
    "#     print(wrapped_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-04 17:09:14,137 - INFO - trying to connect to qdrant\n",
      "2024-06-04 17:09:14,138 - INFO - host\n",
      "2024-06-04 17:09:14,138 - INFO - localhost\n",
      "2024-06-04 17:09:14,138 - INFO - port\n",
      "2024-06-04 17:09:14,138 - INFO - 6333\n"
     ]
    }
   ],
   "source": [
    "from finetuning.utils.openai_helper import OpenAIHandler\n",
    "from finetuning.utils.data_formatter import DataFormatter\n",
    "from finetuning.data_generator import DatasetGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-04 21:34:48,298 - INFO - HTTP Request: POST http://localhost:6333/collections/cleaned_articles/points/scroll \"HTTP/1.1 200 OK\"\n",
      "2024-06-04 21:34:48,323 - INFO - Sending batch to LLM\n",
      "2024-06-04 21:34:49,740 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-04 21:34:49,762 - INFO - Sending batch to LLM\n",
      "2024-06-04 21:34:51,325 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-04 21:34:51,344 - INFO - Sending batch to LLM\n",
      "2024-06-04 21:34:53,345 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-04 21:34:53,353 - INFO - Sending batch to LLM\n",
      "2024-06-04 21:34:54,520 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-04 21:34:54,535 - INFO - Sending batch to LLM\n",
      "2024-06-04 21:34:56,115 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-04 21:34:56,133 - INFO - Sending batch to LLM\n",
      "2024-06-04 21:34:57,433 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-04 21:34:57,453 - INFO - Sending batch to LLM\n",
      "2024-06-04 21:34:59,370 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-04 21:34:59,389 - INFO - Sending batch to LLM\n",
      "2024-06-04 21:35:00,721 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-04 21:35:00,741 - INFO - Sending batch to LLM\n",
      "2024-06-04 21:35:02,151 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-04 21:35:02,163 - INFO - Sending batch to LLM\n",
      "2024-06-04 21:35:04,301 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[{'instruction': 'Write an article on Hidden Road Partners aiming for $120M in Series B funding and a $1B valuation, expanding into cryptocurrency and forex markets, with notable backers like Castle Island Ventures and regulatory compliance efforts related to KYC.',\n",
       "   'content': \" Hidden Road Partners Sets Sights on $120M in Series B Funding, Aiming for $1B Valuation\\n\\n  Citadel Securities-backed prime brokerage firm, Hidden Road Partners, is gearing up for its Series B funding round with an ambitious target of $120 million. The goal? To soar to a market valuation of a cool $1 billion.\\n\\n  Expanding Horizons: Sources familiar with the matter reveal that Hidden Road has its sights set on the cryptocurrency and foreign exchange markets. This move signals the firm's determination to diversify and tap into the potential of these lucrative sectors.\\n\\n  Founded by a Pro: Launched in 2018 by former SAC Capital and Point72 Asset Management employee Marc Asch, Hidden Road wasted no time making waves in the financial world. Its Series A funding round raked in an impressive $50 million.\\n\\n Noteworthy Backers: Castle Island Ventures led the charge during the Series A, with heavyweights like Citadel Securities and Coinbase Ventures joining forces. This star-studded lineup speaks volumes about Hidden Road's appeal and potential.\\n\\n  Prime-Brokerage Powerhouse: With a focus on prime-brokerage services spanning foreign exchange, precious metals, and digital assets, Hidden Road is positioning itself as a one-stop shop for sophisticated investors seeking diverse market exposure.\\n\\n  Binance's KYC Crusade: In line with Binance's commitment to regulatory compliance, Hidden Road and other prime brokers received a directive to bolster their Know Your Customer (KYC) processes. This move underscores Binance's dedication to transparency and adherence to U.S. regulations.\"}],\n",
       " [{'instruction': \"Write a news report about Tether investing $150 million in Bitdeer, a major cryptocurrency mining firm, for a private placement, along with details on Bitdeer's plans for using the capital and its background in the industry.\",\n",
       "   'content': \"Jihan Wus cryptocurrency mining firm Bitdeer is raising new capital from Tether, the operator of the worlds largest stablecoin, the eponymous Tether (USDT). Tether has entered into a subscription agreement with Bitdeer to purchase up to $150 million worth of its shares in a private placement, according to an official announcement on May 31. The private placement includes 18,587,360 Class A ordinary shares and a warrant to purchase up to 5,000,000 additional shares at $10.00 per share. The announcement states that on May 30, the private placement transaction generated $100 million in gross proceeds from the share issuance, with the potential to raise an additional $50 million if the warrant is fully exercised. With fresh net proceeds, Bitdeer plans to fund its further data center expansion, development of an application-specific integrated circuit (ASIC)-based mining rig and other purposes. Established in 2018, Bitdeer is one of the worlds largest cryptocurrency mining companies. It was spun off from Chinese mining machine maker Bitmain.  The firm specializes in both proprietary and host mining and services mining clients' needs with infrastructure and facilities. Bitdeer is known for its vertically integrated business model, meaning that the company has full control over the production of raw materials, assembly, distribution, and sales of its products. We are thrilled to welcome Tether as a significant investor in Bitdeer, Bitdeer chief business officer Linghui Kong said, adding: With Tether's support, we are poised to accelerate our growth and continue our leadership in sustainable and efficient Bitcoin mining. This partnership marks a significant milestone for Bitdeer, and we look forward to achieving great things together. According to Tether CEO Paolo Ardoino, Bitdeer is one of the strongest vertically integrated operators in the Bitcoin mining industry due to its cutting-edge technologies and robust research and development efforts. Related:$2.7B worth of electricity spent on US Bitcoin mining in 2024  analyst Bitdeers proven track record and world-class management team are perfectly aligned with Tethers long-term strategic vision, Ardoino noted, stating: We anticipate close collaboration with Bitdeer across several key infrastructure areas moving forward. Headquartered in Singapore, Bitdeer went public on Nasdaq in April 2023 via a special purpose acquisition company (SPAC) merger with Blue Safari Group Acquisition. Bitdeer originally announced the SPAC deal in November 2021. The news comes a few months after Bitmain CEO Wu assumed the role of CEO at Bitdeer in March, as Kong transitioned to the companys chief business officer.  Wu founded the crypto mining firm in 2020 amid his departure from mining chip manufacturer Bitmain, which he co-founded with Micree Zhan in 2013. Magazine:Crypto voters are already disrupting the 2024 election  and its set to continue Add reaction\"}],\n",
       " [{'instruction': 'Write a news article about Zaros, the first EVM-compatible perpetual decentralized exchange to join the Cointelegraph Accelerator program, highlighting its features, solutions for DeFi traders and liquidity providers, as well as its roadmap for 2024.',\n",
       "   'content': 'Zaros, a perpetual decentralized exchange (DEX), became the first EVM-compatible perpetual DEX to join the Cointelegraph Accelerator program. The platform allows traders to trade perpetual futures and liquidity providers to earn additional yield by providing liquid staking tokens (LSTs) and liquid restaking tokens (LRTs) as liquidity. Decentralized finance (DeFi) traders often face a range of frustrating issues. Liquidity is often scattered across many platforms, making it hard to find the best prices and trading pairs. The user interfaces of DeFi platforms can be overly complex, turning away newcomers and making trading more complicated than it should be. Slow settlement times can be frustrating, causing delays that might lead to missing out on good trade opportunities. High slippage is another problem, where the trade ends up at a different price than expected, eating into profits. Additionally, dealing with multiple blockchains for different assets creates a confusing and fragmented trading environment. To combat liquidity fragmentation, Zaros aims to provide deep liquidity across a wide range of markets, including cryptocurrencies, commodities and forex. The platforms eClusters system and Smart Funding Algorithm group assets with similar risk parameters, allowing for rapid and efficient liquidity allocation to new markets. Zaros employs account abstraction, concealing blockchain technicality in interactions, to enhance user experience. The platform also supports social login and one-click trading for accessibility and ease of use. For high-frequency trading and interoperability, Zaros leverages Chainlinks Data Streams to ensure faster order execution, better settlement prices and protection against front-running  a practice where others can execute trades ahead of a traders for profit. It also allows traders to deposit a wide range of assets as collateral into their Zaros accounts from Arbitrum and Monad, ensuring a seamless cross-margin trading experience. In addition to improving the trading experience, Zaros addresses challenges faced by liquidity providers (LPs) in DeFi. LPs often struggle with limited staking yields, as LSTs and LRTs are typically confined to Ethereums staking yield. DeFi yield-boosting strategies can be risky due to their complexity and potential for significant losses in volatile markets. Additionally, LPs face the risk of liquidation, where sudden market downturns or collateral devaluation can force the sale of assets at a loss. Zaros offers several solutions to address the challenges faced by LPs in DeFi. 70% of trading fees are paid to LP vaults in Ether  ETH  $3,802 , allowing LPs to earn a share of the protocols trading fees in addition to Ethereums staking yield.  ETH   $3,802  The protocol also utilizes USDz, an overcollateralized stablecoin backed by LST vaults, and an eClusters system inspired by Aaves eMode to efficiently distribute credit between markets while remaining delta-neutral, meaning Zaros balances its positions to avoid exposure to market movements. Furthermore, Zaros Liquidity Providing Vaults (ZLP Vaults) represent each LPs stake in the protocols liquidity. It is pegged to the underlying assets of the vault, such as wstETH and weETH, thereby keeping DeFi composability while unlocking an additional yield layer.  Zaros roadmap for 2024. Source: Zaros Zaros envisions a future where decentralized derivatives significantly penetrate centralized finance (CeFi) and TradFi audiences over the next five years. According to Zaros, this transformation can be achieved by focusing on user experience, education and delivering value with safety and credibility. The outcome can foster greater adoption and integration of DeFi in mainstream financial markets. Disclaimer. Cointelegraph does not endorse any content or product on this page. While we aim at providing you with all important information that we could obtain in this sponsored article, readers should do their own research before taking any actions related to the company and carry full responsibility for their decisions, nor can this article be considered as investment advice.'}],\n",
       " [{'instruction': 'Write an article summarizing the guilty verdict against crypto influencer Ian Balina for securities law violations in relation to the SPRK token ICO, emphasizing his failure to disclose financial interests and potential fraud allegations.',\n",
       "   'content': 'Crypto Influencer Ian Balina Found Guilty of Securities Violation! SEC\\'s Case Holds Strong\\n\\n  In a landmark ruling, Judge David Alan Ezra has delivered a verdict that has sent shockwaves through the crypto community. Ian Balina, known for his digital currency expertise, has been found guilty of breaching U.S. securities laws.\\n\\n  The case centered around Balina\\'s involvement in the SPRK token initial coin offering (ICO). The Securities and Exchange Commission (SEC) argued that these tokens were indeed securities and required proper registration and disclosure.\\n\\n  The court\\'s decision hinged on Balina\\'s failure to provide adequate disclosure while promoting SPRK tokens on platforms like YouTube and Telegram. Notably, he conveniently omitted his 30% bonus compensation, a clear violation of Section 17(b) of the Securities Act.\\n\\n  Acting as more than just an influencer, Balina went a step further by organizing an investment pool for SPRK tokens. However, he neglected to reveal his financial stake in Sparkster, the company behind the tokens.\\n\\n  The SEC\\'s investigation revealed that this ICO managed to raise a staggering $30 million from thousands of investors worldwide between April and July 2018.\\n\\n  Balina\\'s response has been swift, with his website dismissing the charges as \"baseless\" and emphasizing that no compensation was received. He even suggests being a victim of fraud himself, pointing fingers at the Sparkster team.'}],\n",
       " [{'instruction': 'Encourage readers to consider investing in #LPP tokens on the MEXC exchange for long-term storage, highlighting its potential as a MemesToken with high yields in the growing Solana ecosystem. Recommend buying LPP within the price range of $0.08 to $0.21 and emphasize the expected price increase after investors accumulate positions. Include links to Telegram, Website, and Discord for further information.',\n",
       "   'content': 'Today, #LPP tokens were listed on the MEXC exchange  \\n\\nThis is a good opportunity to buy tokens of the growing #Solana ecosystem into your investment portfolio for long-term storage\\n\\n#LPP is interesting because \\n\\n It is a MemesToken and as the practice of this year shows - meme tokens show high yields\\n Solana ecosystem tokens are still at the beginning of their journey and, unlike ETH tokens, have a higher growth potential.\\n Now there is a redistribution and after investors accumulate the necessary number of positions to buy the token price will go up. \\n\\n  Buy LPP in the price from $0.08 to $0.21 and hold it   \\n\\n Telegram  |   Website |   Discord'}],\n",
       " [{'instruction': 'Consider investing in Perp DEX token $FXDX as it is expected to increase by 71% according to market trends. Trade $FXDX on MEXC for potential gains.',\n",
       "   'content': 'Perp DEX $FXDX is about to rip 70%  \\n\\n  $FXDX made a nice round bottom as most other DeFi microcaps got decimated. This should tell you whats coming - as soon as $BTC stabilizes, $FXDX will rip up. \\n  Expect it to flip those 3 resistance levels one by one & go above $0.032 - thats a 71% profit.  \\n  Decentralized perpetual futures will be one of the hottest narratives in the 2024-2025 bull run.\\nYou MUST hold some perp DEX tokens in your portfolio - especially small caps like $FXDX. It already has a working product & a nice volume - plus not many people are talking about it on Twitter/Telegram. A really nice catch at these prices.  \\n\\nTrade $FXDX on MEXC'}],\n",
       " [{'instruction': 'Join the Bitlocus (BTL) Trading Competition to compete for a $8,000 prize pool. Register now and start trading $BTL to share $6,000 in rewards. Exclusive $1,000 prize pool for new users. Invite new users to win a share of $1,000. Trade $BTL on the BTL/USDT pair.',\n",
       "   'content': 'Bitlocus (BTL) Trading Competition: $8,000 Prize Pool\\n\\n                       Register Now                                                                                                                                                                                                                                                                                                                                                                                                            \\n\\n Event Period: 11:00 AM, April 15  April 22 (UTC)\\n\\n Trade $BTL to Share $6,000 Rewards\\n New Users Exclusive $1,000 Prize Pool\\n Invite New Users, Win a Share of $1,000\\n\\n  Trade $BTL Here: [  BTL / USDT  ]'}]]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection_name = \"cleaned_articles\"\n",
    "openai_handler = OpenAIHandler()\n",
    "formatter = DataFormatter()\n",
    "generator = DatasetGenerator(openai_handler, formatter)\n",
    "all_contents = generator.fetch_all_cleaned_content(collection_name)\n",
    "training_data = generator.generate_training_data(all_contents[:10], 1)\n",
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-04 17:14:31,782 - INFO - Starting to push data to Comet: cleaned_articles\n",
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/cancamilo/crypto-reporter/49e2cc8a14ec48d789aa7b2e46374f10\n",
      "\n",
      "2024-06-04 17:14:35,687 - INFO - Writing data to file: cleaned_articles.json\n",
      "2024-06-04 17:14:35,688 - INFO - Data written to file successfully\n",
      "2024-06-04 17:14:35,689 - INFO - Artifact created and file added: cleaned_articles.json\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Artifact 'cleaned_articles' version 2.0.0 created (previous was: 1.0.0)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Scheduling the upload of 1 assets for a size of 14.42 KB, this can take some time\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Artifact 'cancamilo/cleaned_articles:2.0.0' has started uploading asynchronously\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name                  : normal_ocean_9191\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/cancamilo/crypto-reporter/49e2cc8a14ec48d789aa7b2e46374f10\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     artifact assets          : 1 (14.42 KB)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     artifacts                : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details      : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename                 : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     git metadata             : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     git-patch (uncompressed) : 1 (797.87 KB)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages       : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook                 : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code              : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Artifact 'cancamilo/cleaned_articles:2.0.0' has been fully uploaded successfully\n",
      "2024-06-04 17:14:38,978 - INFO - Data pushed to Comet successfully and experiment ended\n"
     ]
    }
   ],
   "source": [
    "generator.push_to_comet(training_data, collection_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-04 17:00:12,985 - INFO - HTTP Request: POST http://localhost:6333/collections/cleaned_articles/points/scroll \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_articles = generator.fetch_all_cleaned_content(\"cleaned_articles\")\n",
    "len(cleaned_articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "all_contents = cleaned_articles[140:150]\n",
    "batch_size = 1\n",
    "\n",
    "\n",
    "openai_handler = OpenAIHandler()\n",
    "formatter = DataFormatter()\n",
    "\n",
    "response = []\n",
    "\n",
    "for i in range(0, len(all_contents), batch_size):\n",
    "    batch = all_contents[i : i + batch_size]\n",
    "    initial_prompt = formatter.format_prompt(batch, i)\n",
    "    print(initial_prompt)\n",
    "    batch_result = openai_handler.request(initial_prompt)\n",
    "\n",
    "    # only process batch if response is valid\n",
    "    if len(batch_result) > 0:\n",
    "        response += batch_result\n",
    "        for j in range(i, i + batch_size):\n",
    "            response[j][\"content\"] = all_contents[j]\n",
    "\n",
    "# self.push_to_comet(response, collection_name)\n",
    "response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>323.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>175.275542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>98.662932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>112.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>169.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>219.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1023.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            length\n",
       "count   323.000000\n",
       "mean    175.275542\n",
       "std      98.662932\n",
       "min      13.000000\n",
       "25%     112.000000\n",
       "50%     169.000000\n",
       "75%     219.000000\n",
       "max    1023.000000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(cleaned_articles, columns=[\"content\"])\n",
    "df[\"length\"] = df[\"content\"].apply(lambda x: len(x.split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"content\"].isna().sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-system-_6t_t_f9-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
