{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from qdrant_client import QdrantClient\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Do this to enable importing modules\n",
    "src_path = os.path.join(os.path.abspath(\"\"), \"..\")\n",
    "sys.path.insert(0, src_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MongoDb data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLEAN_MONGODB = False\n",
    "\n",
    "if CLEAN_MONGODB:\n",
    "    from pymongo import MongoClient\n",
    "    host = \"mongodb://localhost:30001,localhost:30002,localhost:30003/?replicaSet=my-replica-set\"\n",
    "    mongo_client = MongoClient(host)\n",
    "\n",
    "    db = mongo_client[\"crypto-articles\"]\n",
    "    db[\"articles\"].drop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qdrant Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-12 13:08:51,161 - INFO - HTTP Request: GET http://localhost:6333/collections \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CollectionsResponse(collections=[CollectionDescription(name='vector_articles'), CollectionDescription(name='cleaned_articles')])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from data_generation.settings import settings\n",
    "from qdrant_client.http.models import Batch, Distance, VectorParams\n",
    "\n",
    "EMBEDDING_SIZE=384\n",
    "CLEAN_COLLECTION = False\n",
    "\n",
    "_client = QdrantClient(\n",
    "    host=settings.QDRANT_DATABASE_HOST,\n",
    "    port=settings.QDRANT_DATABASE_PORT,\n",
    ")\n",
    "\n",
    "\n",
    "if CLEAN_COLLECTION:\n",
    "    _client.delete_collection(collection_name=\"cleaned_articles\")\n",
    "    _client.delete_collection(collection_name=\"vector_articles\")\n",
    "\n",
    "    _client.create_collection(collection_name=\"cleaned_articles\", vectors_config={})\n",
    "    _client.create_collection(collection_name=\"vector_articles\", vectors_config=VectorParams(size=EMBEDDING_SIZE, distance=Distance.COSINE))\n",
    "\n",
    "_client.get_collections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "\n",
    "i = 2\n",
    "\n",
    "# for article in articles:\n",
    "#     wrapped_string = textwrap.fill(article[\"cleaned_content\"], width=100)\n",
    "#     print(\"\\n\")\n",
    "#     print(article[\"source\"])\n",
    "#     print(wrapped_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_generation.utils.openai_helper import OpenAIHandler\n",
    "from data_generation.utils.data_formatter import DataFormatter\n",
    "from data_generation.data_generator import DatasetGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-12 13:15:38,269 - INFO - HTTP Request: POST http://localhost:6333/collections/cleaned_articles/points/scroll \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:15:38,285 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:15:39,795 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:15:39,816 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:15:41,465 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:15:41,482 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:15:43,135 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:15:43,155 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:15:44,602 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:15:44,620 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:15:45,806 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:15:45,821 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:15:47,576 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:15:47,595 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:15:49,475 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:15:49,491 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:15:51,779 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:15:51,804 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:15:54,401 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:15:54,426 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:15:55,820 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:15:55,843 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:15:57,307 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:15:57,324 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:15:58,599 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:15:58,618 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:16:00,648 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:16:00,670 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:16:02,593 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:16:02,615 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:16:04,166 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:16:04,191 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:16:05,426 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:16:05,447 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:16:06,621 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:16:06,644 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:16:07,882 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:16:07,903 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:16:09,571 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:16:09,591 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:16:11,084 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:16:11,106 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:16:12,502 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:16:12,527 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:16:13,856 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:16:13,882 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:16:15,382 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:16:15,409 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:16:16,553 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:16:16,574 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:16:18,466 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:16:18,469 - ERROR - Skipping batch! An error occurred while communicating with API: Expecting ',' delimiter: line 4 column 9 (char 298)\n",
      "2024-06-12 13:16:18,488 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:16:20,002 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:16:20,030 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:16:21,614 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:16:21,615 - ERROR - Skipping batch! An error occurred while communicating with API: Expecting ',' delimiter: line 4 column 9 (char 294)\n",
      "2024-06-12 13:16:21,625 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:16:22,964 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:16:22,983 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:16:24,547 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:16:24,566 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:16:26,578 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:16:26,603 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:16:27,524 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:16:27,550 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:16:29,319 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:16:29,339 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:16:30,368 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:16:30,393 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:16:31,777 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:16:31,805 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:16:33,454 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:16:33,473 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:16:35,570 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:16:35,589 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:16:37,216 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:16:37,240 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:16:38,858 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:16:38,875 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:16:40,012 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:16:40,034 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:16:41,500 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:16:41,552 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:16:42,668 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:16:42,693 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:16:44,098 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:16:44,118 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:16:45,340 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:16:45,363 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:16:48,775 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:16:48,803 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:16:50,107 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:16:50,134 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:16:51,196 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:16:51,219 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:16:52,463 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:16:52,487 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:16:55,014 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:16:55,044 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:16:56,819 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:16:56,827 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:16:57,881 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:16:57,906 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:16:59,526 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:16:59,543 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:17:00,990 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:17:01,004 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:17:02,903 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:17:02,924 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:17:04,137 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:17:04,163 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:17:05,775 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:17:05,800 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:17:07,194 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:17:07,213 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:17:08,538 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:17:08,550 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:17:10,316 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:17:10,333 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:17:11,712 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:17:11,738 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:17:13,147 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:17:13,164 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:17:14,888 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:17:14,908 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:17:16,219 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:17:16,237 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:17:17,830 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:17:17,847 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:17:19,804 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:17:19,824 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:17:21,579 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:17:21,590 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:17:22,986 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:17:23,004 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:17:25,204 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:17:25,225 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:17:26,587 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:17:26,603 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:17:28,712 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:17:28,731 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:17:30,350 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:17:30,366 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:17:33,012 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:17:33,028 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:17:34,650 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:17:34,668 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:17:35,880 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:17:35,894 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:17:37,417 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:17:37,436 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:17:39,053 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:17:39,075 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:17:42,434 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:17:42,452 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:17:43,970 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:17:43,990 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:17:46,120 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:17:46,159 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:17:47,864 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:17:47,882 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:17:49,295 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:17:49,313 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:17:50,743 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:17:50,762 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:17:52,198 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:17:52,216 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:17:53,391 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:17:53,410 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:17:55,377 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:17:55,396 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:17:56,667 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:17:56,682 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:17:58,109 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:17:58,121 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:17:59,841 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:17:59,853 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:18:01,175 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:18:01,193 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:18:02,402 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:18:02,423 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:18:03,937 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:18:03,954 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:18:05,271 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:18:05,287 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:18:06,906 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:18:06,919 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:18:07,691 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:18:07,707 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:18:09,368 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:18:09,388 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:18:11,076 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:18:11,093 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:18:12,673 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:18:12,689 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:18:14,487 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:18:14,524 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:18:15,915 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:18:15,934 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:18:17,763 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:18:17,782 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:18:18,897 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:18:18,914 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:18:20,631 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:18:20,635 - ERROR - Skipping batch! An error occurred while communicating with API: Expecting ',' delimiter: line 4 column 9 (char 336)\n",
      "2024-06-12 13:18:20,649 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:18:22,148 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:18:22,163 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:18:23,497 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:18:23,517 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:18:25,136 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:18:25,151 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:18:26,776 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:18:26,794 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:18:28,204 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:18:28,225 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:18:29,743 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:18:29,763 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:18:31,177 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:18:31,197 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:18:33,225 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:18:33,243 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:18:34,351 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:18:34,369 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:18:35,785 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:18:35,803 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:18:37,321 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:18:37,338 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:18:38,975 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:18:38,985 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:18:40,359 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:18:40,380 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:18:41,825 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:18:41,834 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:18:43,670 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:18:43,703 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:18:44,956 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:18:44,977 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:18:46,024 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:18:46,036 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:18:47,847 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:18:47,865 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:18:49,788 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:18:49,806 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:18:51,104 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:18:51,112 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:18:52,477 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:18:52,498 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:18:54,218 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:18:54,230 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:18:56,115 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:18:56,133 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:18:57,494 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:18:57,515 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:18:59,030 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:18:59,050 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:19:00,669 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:19:00,688 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:19:02,307 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:19:02,323 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:19:04,149 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:19:04,165 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:19:05,688 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:19:05,703 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:19:07,018 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:19:07,036 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:19:08,641 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:19:08,654 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:19:09,987 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:19:10,007 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:19:11,215 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:19:11,229 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:19:13,259 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:19:13,277 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:19:14,799 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:19:14,810 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:19:16,131 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:19:16,150 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:19:17,668 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:19:17,687 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:19:20,740 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:19:20,760 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:19:22,685 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:19:22,704 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:19:24,324 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:19:24,343 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:19:26,175 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:19:26,193 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:19:28,317 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:19:28,338 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:19:30,264 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:19:30,281 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:19:32,665 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:19:32,684 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:19:34,562 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:19:34,580 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:19:35,774 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:19:35,786 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:19:37,123 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:19:37,126 - ERROR - Skipping batch! An error occurred while communicating with API: Expecting ',' delimiter: line 4 column 9 (char 176)\n",
      "2024-06-12 13:19:37,142 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:19:38,659 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:19:38,671 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:19:40,719 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:19:40,741 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:19:42,552 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:19:42,571 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:19:44,660 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:19:44,680 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:19:46,544 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:19:46,561 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:19:47,952 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:19:47,970 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:19:49,616 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:19:49,636 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:19:50,842 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:19:50,861 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:19:51,969 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:19:51,985 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:19:53,201 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:19:53,221 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:19:54,429 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:19:54,449 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:19:55,556 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:19:55,577 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:19:56,909 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:19:56,924 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:19:58,688 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:19:58,707 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:20:01,624 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:20:01,644 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:20:04,362 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:20:04,380 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:20:05,693 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:20:05,711 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:20:06,923 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:20:06,944 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:20:08,664 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:20:08,683 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:20:10,321 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:20:10,332 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:20:11,598 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:20:11,616 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:20:12,759 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:20:12,769 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:20:14,193 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:20:14,213 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:20:15,535 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:20:15,554 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:20:16,790 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:20:16,807 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:20:18,142 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:20:18,153 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:20:19,927 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:20:19,942 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:20:21,052 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:20:21,068 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:20:22,281 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:20:22,298 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:20:24,537 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:20:24,556 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:20:26,205 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:20:26,217 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:20:27,566 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:20:27,587 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:20:31,087 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:20:31,101 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:20:32,729 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:20:32,751 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:20:34,175 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:20:34,194 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:20:35,697 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:20:35,715 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:20:36,926 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:20:36,947 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:20:38,154 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:20:38,165 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:20:40,305 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:20:40,321 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:20:41,431 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:20:41,450 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:20:43,061 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:20:43,080 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:20:45,019 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:20:45,040 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:20:46,142 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:20:46,159 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:20:47,470 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:20:47,479 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:20:49,519 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:20:49,529 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:20:50,729 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:20:50,732 - ERROR - Skipping batch! An error occurred while communicating with API: Expecting ',' delimiter: line 4 column 9 (char 276)\n",
      "2024-06-12 13:20:50,745 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:20:53,260 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:20:53,278 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:20:54,893 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:20:54,914 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:20:56,382 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:20:56,400 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:20:57,917 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:20:57,935 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:20:59,557 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:20:59,577 - INFO - Sending batch to LLM\n",
      "2024-06-12 13:21:00,907 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "collection_name = \"cleaned_articles\"\n",
    "openai_handler = OpenAIHandler()\n",
    "formatter = DataFormatter()\n",
    "generator = DatasetGenerator(openai_handler, formatter)\n",
    "all_contents = generator.fetch_all_cleaned_content(collection_name)\n",
    "training_data = generator.generate_training_data(all_contents[:200], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-12 13:23:39,948 - INFO - Starting to push data to Comet: cleaned_articles\n",
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/cancamilo/crypto-reporter/818bb19458cd47168551642fe8078982\n",
      "\n",
      "2024-06-12 13:23:41,779 - INFO - Writing data to file: cleaned_articles.json\n",
      "2024-06-12 13:23:41,783 - INFO - Data written to file successfully\n",
      "2024-06-12 13:23:41,784 - INFO - Artifact created and file added: cleaned_articles.json\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Artifact 'cleaned_articles' version 6.0.0 created (previous was: 5.0.0)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Scheduling the upload of 1 assets for a size of 334.75 KB, this can take some time\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Artifact 'cancamilo/cleaned_articles:6.0.0' has started uploading asynchronously\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name                  : everyday_jackal_7671\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/cancamilo/crypto-reporter/818bb19458cd47168551642fe8078982\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     artifact assets          : 1 (334.75 KB)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     artifacts                : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details      : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename                 : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     git metadata             : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     git-patch (uncompressed) : 1 (63.10 KB)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages       : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook                 : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code              : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Please wait for assets to finish uploading (timeout is 10800 seconds)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m All assets have been sent, waiting for delivery confirmation\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Artifact 'cancamilo/cleaned_articles:6.0.0' has been fully uploaded successfully\n",
      "2024-06-12 13:23:44,566 - INFO - Data pushed to Comet successfully and experiment ended\n"
     ]
    }
   ],
   "source": [
    "generator.push_to_comet(training_data, collection_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-04 17:00:12,985 - INFO - HTTP Request: POST http://localhost:6333/collections/cleaned_articles/points/scroll \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_articles = generator.fetch_all_cleaned_content(\"cleaned_articles\")\n",
    "len(cleaned_articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "all_contents = cleaned_articles[140:150]\n",
    "batch_size = 1\n",
    "\n",
    "\n",
    "openai_handler = OpenAIHandler()\n",
    "formatter = DataFormatter()\n",
    "\n",
    "response = []\n",
    "\n",
    "for i in range(0, len(all_contents), batch_size):\n",
    "    batch = all_contents[i : i + batch_size]\n",
    "    initial_prompt = formatter.format_prompt(batch, i)\n",
    "    print(initial_prompt)\n",
    "    batch_result = openai_handler.request(initial_prompt)\n",
    "\n",
    "    # only process batch if response is valid\n",
    "    if len(batch_result) > 0:\n",
    "        response += batch_result\n",
    "        for j in range(i, i + batch_size):\n",
    "            response[j][\"content\"] = all_contents[j]\n",
    "\n",
    "response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data can be pushed to commet in order to keep in as an asset. This asset will serve as the input for fine tuning a model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# self.push_to_comet(response, collection_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>323.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>175.275542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>98.662932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>112.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>169.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>219.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1023.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            length\n",
       "count   323.000000\n",
       "mean    175.275542\n",
       "std      98.662932\n",
       "min      13.000000\n",
       "25%     112.000000\n",
       "50%     169.000000\n",
       "75%     219.000000\n",
       "max    1023.000000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(cleaned_articles, columns=[\"content\"])\n",
    "df[\"length\"] = df[\"content\"].apply(lambda x: len(x.split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"content\"].isna().sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-system-_6t_t_f9-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
